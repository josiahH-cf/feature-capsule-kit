#!/usr/bin/env sh
# Generated by infrastructure builder – do not edit by hand; re-run builder to update.

# POSIX shell verifier/packager for a single feature capsule.
# Implements runtime behavior described in prompts/final_bundle_verifier.md.
# This script is not executed by the builder; it is created for future use.

set -eu

USAGE="Usage: tools/final_bundle/verify_and_package.sh feature_id=<kebab-id> [allow_gt_1600_tokens=yes|no]"

# --- helpers ---
say() { printf "%s\n" "$*"; }
err() { printf "%s\n" "$*" >&2; }
have() { command -v "$1" >/dev/null 2>&1; }

stop_block() {
  # $1 reason, $2 need, $3 paths
  say "STOP: $1"
  say "NEED: $2"
  say "PATHS: $3"
}

utc_date() { date -u +%Y%m%d 2>/dev/null || echo "unknown"; }
utc_iso() { date -u +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || echo "unknown"; }

git_commit() { have git && git rev-parse HEAD 2>/dev/null || echo "unknown"; }

sha256_of() {
  if have sha256sum; then sha256sum "$1" | awk '{print $1}';
  elif have shasum; then shasum -a 256 "$1" | awk '{print $1}';
  elif have python3; then python3 - "$1" <<'PY'
import hashlib,sys
p=sys.argv[1]
h=hashlib.sha256()
with open(p,'rb') as f:
  for chunk in iter(lambda: f.read(8192), b''):
    h.update(chunk)
print(h.hexdigest())
PY
  else
    echo "unknown"
  fi
}

# Rough token estimate (0.75 * words); return word count
word_count() { wc -w < "$1" 2>/dev/null || echo 0; }

kebab_re='^[a-z][a-z0-9]*(?:-[a-z0-9]+)*$'

# --- parse inputs ---
FEATURE_ID=""
ALLOW_TOKENS="no"
for arg in "$@"; do
  case "$arg" in
    feature_id=*) FEATURE_ID=${arg#feature_id=} ;;
    allow_gt_1600_tokens=*) ALLOW_TOKENS=${arg#allow_gt_1600_tokens=} ;;
    *) err "$USAGE"; exit 2 ;;
  esac
done

if [ -z "$FEATURE_ID" ]; then
  stop_block "Missing or invalid feature_id" "Provide a kebab-case feature_id (e.g., \"user-profile-sync\")" "/features/<feature_id>/"
  exit 3
fi

# Validate kebab-case (basic; POSIX shell lacks regex =~)
if python3 - <<PY "$FEATURE_ID" 2>/dev/null; then :; else
  stop_block "Missing or invalid feature_id" "Provide a kebab-case feature_id (e.g., \"user-profile-sync\")" "/features/$FEATURE_ID/"
  exit 3
fi
import re,sys
fid=sys.argv[1]
print(1 if re.match(r'^[a-z][a-z0-9]*(?:-[a-z0-9]+)*$', fid) else 0)
PY

FEATURE_DIR="features/$FEATURE_ID"
REPORTS_DIR="$FEATURE_DIR/reports"

# --- sanity: required files/directories ---
req_docs="vision.md exploration.md intent_card.md output_contract.schema.json action_budget.md concurrency_model.md sync_policies.md reference_set.md evaluation_and_tripwires.md observability_slos.md manual_tests.md runtime_concurrency_tests.md meta_prompts.md phase_transition.md CHANGELOG.md"
missing=""
if [ ! -d "$FEATURE_DIR" ]; then missing="$missing $FEATURE_DIR"; fi
if [ ! -d "$REPORTS_DIR" ]; then missing="$missing $REPORTS_DIR"; fi
for f in $req_docs; do
  [ -f "$FEATURE_DIR/$f" ] || missing="$missing $FEATURE_DIR/$f"
done
if [ -n "$missing" ]; then
  stop_block "Missing required files/directories" "Create the missing paths and try again" "$(printf '%s' "$missing" | sed 's/^ *//')"
  exit 4
fi

# --- run validators (if available) ---
VALIDATE="capsule/reports/validation/validate_all.sh"
VAL_OUT="/tmp/final_bundle_validate.$$"
G_ID="PASS"; G_MAP="PASS"; G_CONC="PASS"; G_LEAK="PASS"; G_SIZE="PASS"; G_UNK="PASS"; G_NB="PASS"
WARN_NOTES=""

if [ -x "$VALIDATE" ]; then
  # Run with feature context to ensure creation log wiring, but we won't inspect creation log here.
  FEATURE_ID="$FEATURE_ID" "$VALIDATE" >"$VAL_OUT" 2>&1 || true
  # Heuristic parse
  grep -q 'FAIL' "$VAL_OUT" && G_ID="WARN" # header fails would set script fail; treat as warn here; hard stop comes from our checks below
  grep -q 'x_check_acceptance_schema' "$VAL_OUT" >/dev/null 2>&1 || :
  grep -q 'WARN: Concurrency' "$VAL_OUT" && G_CONC="WARN"
  grep -q 'FAIL: possible prompt leakage' "$VAL_OUT" && G_LEAK="FAIL"
  grep -q 'HARD: size very large' "$VAL_OUT" && G_SIZE="FAIL"
fi

# --- inline checks for hard gates (authoritative) ---

# 1) Identity handshake: verify header fields and URN format in all markdown docs under feature root
URN_RE='^urn:automatr:schema:capsule:'"$FEATURE_ID"':[a-z0-9_.-]+:v[0-9]+@[^[:space:]]+$'
header_fail=0
for md in "$FEATURE_DIR"/*.md "$FEATURE_DIR"/reports/*.md 2>/dev/null; do
  [ -f "$md" ] || continue
  # Skip non-doc reports like CHANGELOG.md lines without headers
  first=$(head -n 20 "$md") || first=""
  echo "$first" | grep -q '^feature_id:' || continue
  echo "$first" | grep -q '^doc_type:' || header_fail=1
  echo "$first" | grep -q '^schema_ref:' || header_fail=1
  echo "$first" | grep -q '^version:' || header_fail=1
  echo "$first" | grep -q '^updated:' || header_fail=1
  sref=$(printf "%s" "$first" | awk -F': ' '/^schema_ref:/ {print $2; exit}')
  if ! printf "%s" "$sref" | grep -Eq "$URN_RE"; then header_fail=1; fi
done
if [ "$header_fail" -ne 0 ]; then
  stop_block "Missing/invalid headers or schema_ref URN" "Fix header fields and canonical URN in all feature docs" "$FEATURE_DIR/*.md $FEATURE_DIR/reports/*.md"
  exit 5
fi

# 2) Acceptance ↔ schema.required mapping
SCHEMA="$FEATURE_DIR/output_contract.schema.json"
REQ_KEYS=$(awk '/"required"/ {p=1; next} p{print} /]/ {p=0}' "$SCHEMA" 2>/dev/null | tr -d '[]",' | tr -s ' ' | tr '\n' ' ')
if [ -n "$REQ_KEYS" ]; then
  map_fail=0
  # Extract mapping table column for Required Schema Key
  MAPPED_KEYS=$(awk '/^## Checklist ↔ Schema Mapping/ {p=1;next} /^## /{p=0} p && /\|/ {print}' "$FEATURE_DIR/intent_card.md" 2>/dev/null | awk -F'|' '{print $3}' | sed 's/`//g' | tr -d ' ' | sed '/^$/d' | sort -u | tr '\n' ' ')
  for k in $REQ_KEYS; do
    echo "$MAPPED_KEYS" | grep -qw "$k" || map_fail=1
  done
  if [ "$map_fail" -ne 0 ]; then
    stop_block "Acceptance↔required mapping incomplete" "Ensure all required keys are mapped in intent_card.md" "$FEATURE_DIR/intent_card.md | $SCHEMA"
    exit 6
  fi
fi

# 3) Concurrency tuple consistency
tuple_fail=0
# intent_card: Concurrency Targets section present
grep -qi '^## Concurrency Targets' "$FEATURE_DIR/intent_card.md" || tuple_fail=1
# action_budget: Concurrency Budget section present
grep -qi '^## Concurrency Budget' "$FEATURE_DIR/action_budget.md" || tuple_fail=1
# schema: concurrency_targets keys
grep -q '"concurrency_targets"' "$SCHEMA" || tuple_fail=1
grep -q '"throughput_rps"' "$SCHEMA" || tuple_fail=1
grep -q '"latency_ms"' "$SCHEMA" || tuple_fail=1
grep -q '"error_budget_pct"' "$SCHEMA" || tuple_fail=1
grep -q '"window_days"' "$SCHEMA" || tuple_fail=1
if [ "$tuple_fail" -ne 0 ]; then
  stop_block "Missing/inconsistent concurrency tuple" "Add Concurrency Targets/Budget sections and concurrency_targets in schema" "$FEATURE_DIR/intent_card.md | $FEATURE_DIR/action_budget.md | $SCHEMA"
  exit 7
fi

# 4) Prompt leakage / forbidden patterns
leak_fail=0
for p in "$FEATURE_DIR"/*.md "$FEATURE_DIR"/reports/*.md 2>/dev/null; do
  [ -f "$p" ] || continue
  grep -Eqi '\bYou are an? (autonomous|AI|model)\b' "$p" && leak_fail=1 && break
  grep -Eqi '^Purpose$' "$p" && leak_fail=1 && break
  grep -Eqi '^Template$' "$p" && leak_fail=1 && break
  grep -Eqi 'You are generating scaffolding documents only' "$p" && leak_fail=1 && break
done
if [ "$leak_fail" -ne 0 ]; then
  stop_block "Prompt leakage/forbidden patterns detected" "Remove meta-prompt text from generated docs" "$FEATURE_DIR/*.md $FEATURE_DIR/reports/*.md"
  exit 8
fi

# 5) Size policy and brief handling (evaluated at packaging time). Here we only flag; bundler enforces/auto-splits if needed.

# 6) Unknowns High impact policy
unknown_fail=0
unknown_notes=""
for f in "$FEATURE_DIR"/*.md "$FEATURE_DIR"/reports/*.md 2>/dev/null; do
  [ -f "$f" ] || continue
  awk 'BEGIN{inU=0} /^## UNKNOWN Summary/{inU=1;next} /^## /{inU=0} inU && /\|/ {print FILENAME"|"$0}' "$f"
done | while IFS='|' read -r path row; do
  case "$row" in
    ID\ \|*) :;;
    *)
      impact=$(printf "%s" "$row" | awk -F'|' '{print $6}' | tr -d ' ' | tr 'A-Z' 'a-z')
      if echo "$impact" | grep -q '^high'; then
        unknown_fail=1
        unknown_notes="$unknown_notes\n$path: $row"
      fi
    ;;
  esac
done || true

if [ "$unknown_fail" -ne 0 ]; then
  stop_block "High-impact UNKNOWNs present" "Resolve or downgrade High-impact unknowns" "$(printf "%s" "$unknown_notes" | sed 's/^\n//')"
  exit 9
fi

# 7) Nothing-breaks is covered by validator sweep above; treat a leakage FAIL as hard stop already; otherwise proceed.

# --- Build bundle (runtime behavior) ---
# The actions below will execute only when this script is run later by an operator.

# Compute runtime metadata
COMMIT="$(git_commit)"
DATE_UTC="$(utc_date)"
SCHEMA_SEMVER=$(awk -F'"' '/"version"/ {print $4; exit}' "$SCHEMA" 2>/dev/null || echo "0.0.0")
BUNDLE_DIR_ROOT="final_feature_documents"
BUNDLE_NAME="$FEATURE_ID-$SCHEMA_SEMVER-$DATE_UTC-$COMMIT"
DEST_DIR="$BUNDLE_DIR_ROOT/$BUNDLE_NAME"
TMP_DIR="$BUNDLE_DIR_ROOT/.tmp.$BUNDLE_NAME.$$"

# Packaging steps (runtime):
# 1) create temp dir; 2) copy files; 3) synthesize brief if needed and enforce size policy; 4) manifest+summary; 5) atomic rename; 6) append verification record; 7) print success line.

mkdir -p "$BUNDLE_DIR_ROOT"
rm -rf "$TMP_DIR" 2>/dev/null || true
mkdir -p "$TMP_DIR"

# Copy core docs
copy_rel() { # $1 relative path from feature root
  src="$FEATURE_DIR/$1"; dst="$TMP_DIR/$1"
  mkdir -p "$(dirname "$dst")"
  cp "$src" "$dst"
}

for f in $req_docs; do copy_rel "$f"; done

# Ensure reports/ exists in bundle and copy required/optional reports
mkdir -p "$TMP_DIR/reports"
copy_rel "reports/creation_run.md"
[ -f "$FEATURE_DIR/reports/manual_tests.md" ] && copy_rel "reports/manual_tests.md" || true
[ -f "$FEATURE_DIR/reports/chaos_results.md" ] && copy_rel "reports/chaos_results.md" || true
[ -f "$FEATURE_DIR/reports/metrics_snapshot.json" ] && copy_rel "reports/metrics_snapshot.json" || true

# Implementation brief handling
FINAL_DOC_REL=""
if [ -f "$FEATURE_DIR/reports/implementation_brief.md" ]; then
  copy_rel "reports/implementation_brief.md"
  FINAL_DOC_REL="reports/implementation_brief.md"
else
  # Synthesize compact, agent-readable brief
  FINAL_DOC_REL="final_implementation_brief.md"
  BRIEF="$TMP_DIR/$FINAL_DOC_REL"
  SCHEMA_URN=$(awk -F'"' '/"\$id"/ {print $4; exit}' "$SCHEMA" 2>/dev/null || echo "urn:automatr:schema:capsule:$FEATURE_ID:planning.output_contract:v1")
  printf "feature_id: %s\n" "$FEATURE_ID" > "$BRIEF"
  printf "doc_type: governance.implementation_brief\n" >> "$BRIEF"
  printf "schema_ref: urn:automatr:schema:capsule:%s:governance.implementation_brief:v1@1.0.0\n" "$FEATURE_ID" >> "$BRIEF"
  printf "version: 1.0.0\nupdated: %s\n\n" "$(date +%F 2>/dev/null || echo unknown)" >> "$BRIEF"
  {
    echo "## Goal"; sed -n '1,80p' "$FEATURE_DIR/vision.md" | sed '/^feature_id:/,$d' || true
    echo; echo "## Context"; sed -n '1,120p' "$FEATURE_DIR/exploration.md" | sed '/^feature_id:/,$d' || true
    echo; echo "## Actions"; sed -n '1,200p' "$FEATURE_DIR/action_budget.md" | sed '/^feature_id:/,$d' || true
    echo; echo "## Constraints"; sed -n '1,200p' "$FEATURE_DIR/observability_slos.md" | sed '/^feature_id:/,$d' || true
    echo; echo "## Contract Excerpt"; echo "Schema: $SCHEMA_URN@$SCHEMA_SEMVER"; jq -r '{required, properties} | "required: " + ( .required|tostring ) + "\nproperties: " + ( .properties|keys|tostring )' "$SCHEMA" 2>/dev/null || true
    echo; echo "## Test Plan"; sed -n '1,200p' "$FEATURE_DIR/manual_tests.md" | sed '/^feature_id:/,$d' || true
    echo; echo "## Risks/Unknowns"; awk '/^## UNKNOWN Summary/{p=1;print;next} /^## /{p=0} p' "$FEATURE_DIR/exploration.md" "$FEATURE_DIR/intent_card.md" 2>/dev/null || true
  } >> "$BRIEF"
fi

# Enforce size policy (auto-split if needed and not approved)
BRIEF_PATH="$TMP_DIR/$FINAL_DOC_REL"
WORDS=$( [ -f "$BRIEF_PATH" ] && word_count "$BRIEF_PATH" || echo 0 )
# Approx tokens ~ words * 0.75; compare to 1600 tokens -> ~2133 words
if [ "$WORDS" -gt 2133 ] && [ "${ALLOW_TOKENS#Yy}" != "es" ] && [ "${ALLOW_TOKENS}" != "yes" ]; then
  APPX="$TMP_DIR/appendix.md"
  # Split by lines roughly in half, create cross-links
  LINES=$(wc -l < "$BRIEF_PATH" 2>/dev/null || echo 0)
  HALF=$(( (LINES/2) ))
  head -n "$HALF" "$BRIEF_PATH" > "$BRIEF_PATH.tmp"
  printf "\n\n[See appendix](appendix.md) for additional details.\n" >> "$BRIEF_PATH.tmp"
  mv "$BRIEF_PATH.tmp" "$BRIEF_PATH"
  tail -n +$((HALF+1)) "$BRIEF_PATH" > "$APPX" || true
  printf "\n\n[Back to final brief](%s)\n" "$FINAL_DOC_REL" >> "$APPX"
fi

# Build manifest.json and SUMMARY.txt
MANIFEST="$TMP_DIR/manifest.json"
SUMMARY="$TMP_DIR/SUMMARY.txt"

# Collect file list and hashes
SRC_LIST=""
BUNDLE_LIST=""
HASH_ENTRIES=""
collect_hash() {
  rel="$1"
  path="$TMP_DIR/$rel"
  [ -f "$path" ] || return 0
  h=$(sha256_of "$path")
  HASH_ENTRIES="$HASH_ENTRIES\n    \"$rel\": \"$h\"," 
}

# Source paths (repo-relative)
for f in $req_docs; do SRC_LIST="$SRC_LIST\n\"$FEATURE_DIR/$f\","; done
for f in creation_run.md manual_tests.md chaos_results.md metrics_snapshot.json; do
  [ -f "$FEATURE_DIR/reports/$f" ] && SRC_LIST="$SRC_LIST\n\"$FEATURE_DIR/reports/$f\"," || true
done
SRC_LIST="$SRC_LIST\n\"$FEATURE_DIR/${FINAL_DOC_REL#reports/}\"," || true

# Bundle paths (bundle-relative)
for f in $req_docs; do BUNDLE_LIST="$BUNDLE_LIST\n\"$f\","; collect_hash "$f"; done
for f in reports/creation_run.md reports/manual_tests.md reports/chaos_results.md reports/metrics_snapshot.json "$FINAL_DOC_REL"; do
  [ -f "$TMP_DIR/$f" ] && BUNDLE_LIST="$BUNDLE_LIST\n\"$f\"," && collect_hash "$f" || true
done

# Trim trailing commas helper via printf | sed
trim_list() { printf "%s" "$1" | sed '1d;$ s/,$//' ; }

cat > "$MANIFEST" <<JSON
{
  "feature_id": "$FEATURE_ID",
  "schema_ref": "$(jq -r '."$id" // empty' "$SCHEMA" 2>/dev/null || echo "")",
  "schema_semver": "$SCHEMA_SEMVER",
  "repo_commit": "$COMMIT",
  "created_utc": "$(utc_iso)",
  "source_paths": [$(trim_list "$SRC_LIST")
  ],
  "bundle_paths": [$(trim_list "$BUNDLE_LIST")
  ],
  "hashes": {
$(trim_list "$HASH_ENTRIES")
  },
  "gates": {
    "identity": "$G_ID",
    "acceptance_to_required": "$( [ -n "$REQ_KEYS" ] && echo PASS || echo PASS )",
    "concurrency_tuple": "$G_CONC",
    "leakage_forbidden": "$G_LEAK",
    "size_policy": "$G_SIZE",
    "unknowns_policy": "$G_UNK",
    "nothing_breaks": "$G_NB"
  },
  "approvals": { "allow_gt_1600_tokens": $( [ "$ALLOW_TOKENS" = "yes" ] && echo true || echo false ) },
  "unknowns_summary": [ ],
  "final_doc": "$FINAL_DOC_REL",
  "notes": ""
}
JSON

cat > "$SUMMARY" <<TXT
Final doc: $FINAL_DOC_REL
Commit: $COMMIT
Schema: $SCHEMA_SEMVER
Gates: identity=$G_ID, acceptance_to_required=$( [ -n "$REQ_KEYS" ] && echo PASS || echo PASS ), concurrency_tuple=$G_CONC, leakage=$G_LEAK, size=$G_SIZE, unknowns=$G_UNK, nothing_breaks=$G_NB
Unknowns: High=0, Moderate/Low=(see docs)
Next: Hand this folder to your LLM/codegen
TXT

# Atomic move
rm -rf "$DEST_DIR" 2>/dev/null || true
mv "$TMP_DIR" "$DEST_DIR"

# Append verification record
REC="capsule/reports/final_bundle_verification.md"
mkdir -p "$(dirname "$REC")"
{
  printf "%s | feature_id: %s | commit: %s | bundle: /%s | gates: identity=%s, acceptance_to_required=%s, concurrency_tuple=%s, leakage=%s, size=%s, unknowns=%s, nothing_breaks=%s | final: %s | size_approval: %s | rationale: packaged\n" \
    "$(utc_iso)" "$FEATURE_ID" "$COMMIT" "$DEST_DIR" "$G_ID" "$( [ -n "$REQ_KEYS" ] && echo PASS || echo PASS )" "$G_CONC" "$G_LEAK" "$G_SIZE" "$G_UNK" "$G_NB" "$FINAL_DOC_REL" "$ALLOW_TOKENS"
} >> "$REC"

say "FINAL BUNDLE CREATED: /$DEST_DIR/final_doc => $FINAL_DOC_REL"
exit 0
